DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x35aefd28 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x35aefd28, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2f9875670006, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x35aefd28, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x35aefd28-0x34b2f9875670006 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400162,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400162,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3cc425b2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x35aefd28 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x35aefd28, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@48922dec
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2f9875670007, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x35aefd28, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x35aefd28-0x34b2f9875670007 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400163,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x35aefd28-0x34b2f9875670007, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400163,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670006, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900400163,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x34b2f9875670006 after 38ms
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x103b8d23 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x103b8d23, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 WARN main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 1000ms before retry #0...
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2f9875670008, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x103b8d23, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x103b8d23-0x34b2f9875670008 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400164,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2f9875670008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400164,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@64375c2a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x103b8d23 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x103b8d23, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@10c7e8b9
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x34b2f9875670008 after 44ms
 WARN main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 1000ms before retry #0...
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5aab5443 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x5aab5443, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fa6122b0000, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5aab5443, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5aab5443-0x34b2fa6122b0000 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0000, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400321,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0000, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400321,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@33540d0c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0000, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900400321,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0000, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900400321,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 460 bytes
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0000, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900400321,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 471 }, totalSize: 489 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG IPC Client (1738073591) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (1738073591) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1738073591) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 12 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2823796f connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4ac8e, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2823796f-0x14b2ef08aa4ac8e connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400418,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400420,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7a6d4080, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,85900400423,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900400423,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 0, totalSize: 6 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 1 method_name: "DisableTable" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 1, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x2823796f connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@19d244d9
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4ac8f, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x2823796f-0x14b2ef08aa4ac8f connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400431,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x2823796f-0x14b2ef08aa4ac8f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400431,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900400431,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 2
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 2, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 3 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 4 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 4, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@19d244d9
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x14b2ef08aa4ac8f
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x14b2ef08aa4ac8f
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8f, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900400432,0  request:: null response:: null
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x14b2ef08aa4ac8f : Unable to read additional data from server sessionid 0x14b2ef08aa4ac8f, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x14b2ef08aa4ac8f
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x14b2ef08aa4ac8f closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,85900400432,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a3630303030ffffffe33125ffffffdaffffff8dffffffd1ffffffff415042554682,s{85900400374,85900400429,1422433779095,1422433979116,4,0,0,0,31,0,85900400374} 
 DEBUG main org.apache.hadoop.hbase.client.HBaseAdmin - Sleeping= 100ms, waiting for all regions to be disabled in dsp_tanx_usefull
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x2823796f connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3e3bb1f6
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4ac90, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x2823796f-0x14b2ef08aa4ac90 connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac90, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400433,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x2823796f-0x14b2ef08aa4ac90, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac90, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400434,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,85900400434,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 5 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 5, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 6 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 7 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 7, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3e3bb1f6
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x14b2ef08aa4ac90
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x14b2ef08aa4ac90
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac90, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900400436,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x14b2ef08aa4ac90
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x14b2ef08aa4ac90 closed
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x14b2ef08aa4ac90 : Unable to read additional data from server sessionid 0x14b2ef08aa4ac90, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,85900400436,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a3630303030ffffffe33125ffffffdaffffff8dffffffd1ffffffff415042554682,s{85900400374,85900400429,1422433779095,1422433979116,4,0,0,0,31,0,85900400374} 
 DEBUG main org.apache.hadoop.hbase.client.HBaseAdmin - Sleeping= 200ms, waiting for all regions to be disabled in dsp_tanx_usefull
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x2823796f connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4f1e8225
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fa6122b0006, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x2823796f, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x2823796f-0x34b2fa6122b0006 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900400439,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x2823796f-0x34b2fa6122b0006, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900400439,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,85900400439,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 8 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 8, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 9 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 10 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 10, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4f1e8225
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x34b2fa6122b0006
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x34b2fa6122b0006
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fa6122b0006, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900400440,0  request:: null response:: null
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x34b2fa6122b0006 : Unable to read additional data from server sessionid 0x34b2fa6122b0006, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x34b2fa6122b0006
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x34b2fa6122b0006 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 10,4  replyHeader:: 10,85900400440,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a3630303030ffffff974472ffffff92ffffff8dfffffff229ffffffd75042554681,s{85900400374,85900400437,1422433779095,1422433981197,5,0,0,0,31,0,85900400374} 
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 11 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 11, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 12 method_name: "DeleteTable" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 12, totalSize: 4 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4ac8e, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,85900400441,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 13 method_name: "Scan" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 13, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 14 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 14, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 15 method_name: "GetTableDescriptors" request_param: true
 DEBUG IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1018418577) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 15, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted dsp_tanx_usefull
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x30f97aff connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x30f97aff, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60cfc5, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x30f97aff, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x30f97aff-0x24b2ef08b60cfc5 connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60cfc5, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900451611,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60cfc5, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900451632,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@66ecc0f8, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60cfc5, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,85900451731,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60cfc5, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900451744,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 0, totalSize: 6 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 1 method_name: "DisableTable" request_param: true
 DEBUG IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (384987932) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 1 exception { exception_class_name: "org.apache.hadoop.hbase.TableNotEnabledException" stack_trace: "org.apache.hadoop.hbase.TableNotEnabledException: dsp_tanx_usefull\n\tat org.apache.hadoop.hbase.master.handler.DisableTableHandler.prepare(DisableTableHandler.java:100)\n\tat org.apache.hadoop.hbase.master.HMaster.disableTable(HMaster.java:2214)\n\tat org.apache.hadoop.hbase.master.HMaster.disableTable(HMaster.java:2225)\n\tat org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:41475)\n\tat org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2029)\n\tat org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)\n\tat org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n" do_not_retry: true }, totalSize: 1064 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x736e68a0 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb141633337, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x736e68a0-0x34b2fb141633337 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900480804,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900480804,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@27ca0e3b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x736e68a0 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3cf7366d
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e11b, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x736e68a0-0x24b2ef08b60e11b connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900480805,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x736e68a0-0x24b2ef08b60e11b, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900480805,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900480805,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 2, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3cf7366d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x24b2ef08b60e11b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x24b2ef08b60e11b
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11b, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900480806,0  request:: null response:: null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x24b2ef08b60e11b : Unable to read additional data from server sessionid 0x24b2ef08b60e11b, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x24b2ef08b60e11b
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x24b2ef08b60e11b closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main com.pxene.report.ReportMRHbase - ~~ table already exists!
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 4,3  replyHeader:: 4,85900480806,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900480806,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: stopped, connections 1
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x34b2fb141633337 after 58ms
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closing ipc connection to pxene01/42.123.70.33:60000: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene01/42.123.70.33:60000]
 org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene01/42.123.70.33:60000]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:532)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$BlockingStub.isMasterRunning(MasterProtos.java:43617)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.isMasterRunning(HConnectionManager.java:1667)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStubNoRetries(HConnectionManager.java:1576)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStub(HConnectionManager.java:1602)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.makeStub(HConnectionManager.java:1656)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveMasterService(HConnectionManager.java:1863)
	at org.apache.hadoop.hbase.client.HBaseAdmin$MasterCallable.prepare(HBaseAdmin.java:3362)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:116)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3389)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTableAsync(HBaseAdmin.java:942)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:974)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:1009)
	at com.pxene.report.ReportMRHbase.deleteTable(ReportMRHbase.java:189)
	at com.pxene.report.ReportMRHbase.creatTable(ReportMRHbase.java:169)
	at com.pxene.report.ReportMRHbase.main(ReportMRHbase.java:43)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closed
 INFO main org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation - getMaster attempt 1 of 35 failed; retrying after sleep of 100, exception=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene01/42.123.70.33:60000]
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 6,3  replyHeader:: 6,85900480813,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,85900480813,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene01/42.123.70.33:60000 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closing ipc connection to pxene01/42.123.70.33:60000: This server is in the failed servers list: pxene01/42.123.70.33:60000
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$BlockingStub.isMasterRunning(MasterProtos.java:43617)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.isMasterRunning(HConnectionManager.java:1667)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStubNoRetries(HConnectionManager.java:1576)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStub(HConnectionManager.java:1602)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.makeStub(HConnectionManager.java:1656)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveMasterService(HConnectionManager.java:1863)
	at org.apache.hadoop.hbase.client.HBaseAdmin$MasterCallable.prepare(HBaseAdmin.java:3362)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:116)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3389)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTableAsync(HBaseAdmin.java:942)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:974)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:1009)
	at com.pxene.report.ReportMRHbase.deleteTable(ReportMRHbase.java:189)
	at com.pxene.report.ReportMRHbase.creatTable(ReportMRHbase.java:169)
	at com.pxene.report.ReportMRHbase.main(ReportMRHbase.java:43)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closed
 INFO main org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation - getMaster attempt 2 of 35 failed; retrying after sleep of 201, exception=com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 8,3  replyHeader:: 8,85900480813,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,85900480813,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene01/42.123.70.33:60000 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closing ipc connection to pxene01/42.123.70.33:60000: This server is in the failed servers list: pxene01/42.123.70.33:60000
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$BlockingStub.isMasterRunning(MasterProtos.java:43617)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.isMasterRunning(HConnectionManager.java:1667)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStubNoRetries(HConnectionManager.java:1576)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStub(HConnectionManager.java:1602)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.makeStub(HConnectionManager.java:1656)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveMasterService(HConnectionManager.java:1863)
	at org.apache.hadoop.hbase.client.HBaseAdmin$MasterCallable.prepare(HBaseAdmin.java:3362)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:116)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3389)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTableAsync(HBaseAdmin.java:942)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:974)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:1009)
	at com.pxene.report.ReportMRHbase.deleteTable(ReportMRHbase.java:189)
	at com.pxene.report.ReportMRHbase.creatTable(ReportMRHbase.java:169)
	at com.pxene.report.ReportMRHbase.main(ReportMRHbase.java:43)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closed
 INFO main org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation - getMaster attempt 3 of 35 failed; retrying after sleep of 300, exception=com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 10,3  replyHeader:: 10,85900480813,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,85900480813,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene01/42.123.70.33:60000 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closing ipc connection to pxene01/42.123.70.33:60000: This server is in the failed servers list: pxene01/42.123.70.33:60000
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$BlockingStub.isMasterRunning(MasterProtos.java:43617)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.isMasterRunning(HConnectionManager.java:1667)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStubNoRetries(HConnectionManager.java:1576)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$StubMaker.makeStub(HConnectionManager.java:1602)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$MasterServiceStubMaker.makeStub(HConnectionManager.java:1656)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveMasterService(HConnectionManager.java:1863)
	at org.apache.hadoop.hbase.client.HBaseAdmin$MasterCallable.prepare(HBaseAdmin.java:3362)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:116)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3389)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTableAsync(HBaseAdmin.java:942)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:974)
	at org.apache.hadoop.hbase.client.HBaseAdmin.disableTable(HBaseAdmin.java:1009)
	at com.pxene.report.ReportMRHbase.deleteTable(ReportMRHbase.java:189)
	at com.pxene.report.ReportMRHbase.creatTable(ReportMRHbase.java:169)
	at com.pxene.report.ReportMRHbase.main(ReportMRHbase.java:43)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closed
 INFO main org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation - getMaster attempt 4 of 35 failed; retrying after sleep of 504, exception=com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 12,3  replyHeader:: 12,85900480813,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 13,4  replyHeader:: 13,85900480813,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 7 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 7, totalSize: 6 bytes
 INFO main org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation - getMaster attempt 5 of 35 failed; retrying after sleep of 1005, exception=com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene01/42.123.70.33:60000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 8 method_name: "DisableTable" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 8, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x736e68a0 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6eadc941
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x34b2fb141633337 after 72ms
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e11c, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x736e68a0-0x24b2ef08b60e11c connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900480836,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x736e68a0-0x24b2ef08b60e11c, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900480836,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 14,4  replyHeader:: 14,85900480836,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: closed
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: stopped, connections 1
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 9 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 9, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 10 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 11 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 11, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6eadc941
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x24b2ef08b60e11c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x24b2ef08b60e11c
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11c, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900480844,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x24b2ef08b60e11c
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x24b2ef08b60e11c : Unable to read additional data from server sessionid 0x24b2ef08b60e11c, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x24b2ef08b60e11c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 15,4  replyHeader:: 15,85900480844,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a36303030306bfffffff43543582131ffffff995042554681,s{85900479303,85900480820,1422436267803,1422438437608,5,0,0,0,31,0,85900479303} 
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 12 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 2
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 12, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 13 method_name: "DeleteTable" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 13, totalSize: 4 bytes
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 16,4  replyHeader:: 16,85900480845,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 14 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 14, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 15 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 15, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 16 method_name: "GetTableDescriptors" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 16, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted dsp_tanx_usefull
 INFO main com.pxene.report.ReportMRHbase - ~~ delete table dsp_tanx_usefull ok.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 17 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 17, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 18 method_name: "CreateTable" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 18, totalSize: 4 bytes
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 17,4  replyHeader:: 17,85900480853,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 19 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 19, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 20 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 20 cell_block_meta { length: 1881 }, totalSize: 1909 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 21 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 21, totalSize: 11 bytes
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 18,4  replyHeader:: 18,85900480859,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 22 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 22, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 23 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 23 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 24 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 24, totalSize: 11 bytes
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x736e68a0 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@577a2815
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e11d, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x736e68a0, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x736e68a0-0x24b2ef08b60e11d connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900480860,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x736e68a0-0x24b2ef08b60e11d, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900480860,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 19,4  replyHeader:: 19,85900480860,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 25 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 25, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 26 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 26 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 27 method_name: "Scan" request_param: true
 DEBUG IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1247407789) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 27, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@577a2815
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x24b2ef08b60e11d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x24b2ef08b60e11d
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e11d, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900480861,0  request:: null response:: null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x24b2ef08b60e11d : Unable to read additional data from server sessionid 0x24b2ef08b60e11d, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x24b2ef08b60e11d
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x24b2ef08b60e11d closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb141633337, packet:: clientPath:null serverPath:null finished:false header:: 20,4  replyHeader:: 20,85900480861,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a3630303030ffffffd4ffffff85a4dfffffffdffffff8e70585042554680,s{85900480852,85900480855,1422438456553,1422438456789,2,0,0,0,31,0,85900480852} 
 INFO main com.pxene.report.ReportMRHbase - ~~ create table dsp_tanx_usefull ok.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.mapoutput.value.class is deprecated. Instead, use mapreduce.map.output.value.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.name is deprecated. Instead, use mapreduce.job.name
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.mapoutput.key.class is deprecated. Instead, use mapreduce.map.output.key.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.df.interval is deprecated. Instead, use fs.df.interval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.tracker.http.address is deprecated. Instead, use mapreduce.tasktracker.http.address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.max.objects is deprecated. Instead, use dfs.namenode.max.objects
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.userlog.retain.hours is deprecated. Instead, use mapreduce.job.userlog.retain.hours
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.local.dir.minspacestart is deprecated. Instead, use mapreduce.tasktracker.local.dir.minspacestart
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.shuffle.read.timeout is deprecated. Instead, use mapreduce.reduce.shuffle.read.timeout
 INFO main org.apache.hadoop.conf.Configuration.deprecation - io.sort.spill.percent is deprecated. Instead, use mapreduce.map.sort.spill.percent
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.parallel.copies is deprecated. Instead, use mapreduce.reduce.shuffle.parallelcopies
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.local.dir.minspacekill is deprecated. Instead, use mapreduce.tasktracker.local.dir.minspacekill
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.profile is deprecated. Instead, use mapreduce.task.profile
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.data.dir is deprecated. Instead, use dfs.datanode.data.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.heartbeats.in.second is deprecated. Instead, use mapreduce.jobtracker.heartbeats.in.second
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.healthChecker.interval is deprecated. Instead, use mapreduce.tasktracker.healthchecker.interval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.temp.dir is deprecated. Instead, use mapreduce.cluster.temp.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - jobclient.completion.poll.interval is deprecated. Instead, use mapreduce.client.completion.pollinterval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.persist.jobstatus.active is deprecated. Instead, use mapreduce.jobtracker.persist.jobstatus.active
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.name.dir is deprecated. Instead, use dfs.namenode.name.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compression.codec is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.codec
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.shuffle.merge.percent is deprecated. Instead, use mapreduce.reduce.shuffle.merge.percent
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.input.buffer.percent is deprecated. Instead, use mapreduce.reduce.input.buffer.percent
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.cache.levels is deprecated. Instead, use mapreduce.jobtracker.taskcache.levels
 INFO main org.apache.hadoop.conf.Configuration.deprecation - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.jobtracker.instrumentation is deprecated. Instead, use mapreduce.jobtracker.instrumentation
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.userlog.limit.kb is deprecated. Instead, use mapreduce.task.userlog.limit.kb
 INFO main org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.speculative.execution.slowNodeThreshold is deprecated. Instead, use mapreduce.job.speculative.slownodethreshold
 INFO main org.apache.hadoop.conf.Configuration.deprecation - fs.checkpoint.dir is deprecated. Instead, use dfs.namenode.checkpoint.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.map.max.skip.records is deprecated. Instead, use mapreduce.map.skip.maxrecords
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.block.size is deprecated. Instead, use dfs.blocksize
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.access.time.precision is deprecated. Instead, use dfs.namenode.accesstime.precision
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.jobhistory.lru.cache.size is deprecated. Instead, use mapreduce.jobtracker.jobhistory.lru.cache.size
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.persist.jobstatus.hours is deprecated. Instead, use mapreduce.jobtracker.persist.jobstatus.hours
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.handler.count is deprecated. Instead, use mapreduce.jobtracker.handler.count
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
 INFO main org.apache.hadoop.conf.Configuration.deprecation - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.profile.maps is deprecated. Instead, use mapreduce.task.profile.maps
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.replication.min is deprecated. Instead, use dfs.namenode.replication.min
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.name.edits.dir is deprecated. Instead, use dfs.namenode.edits.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.replication.considerLoad is deprecated. Instead, use dfs.namenode.replication.considerLoad
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.dns.nameserver is deprecated. Instead, use mapreduce.tasktracker.dns.nameserver
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.taskmemorymanager.monitoring-interval is deprecated. Instead, use mapreduce.tasktracker.taskmemorymanager.monitoringinterval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.expiry.interval is deprecated. Instead, use mapreduce.jobtracker.expire.trackers.interval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.balance.bandwidthPerSec is deprecated. Instead, use dfs.datanode.balance.bandwidthPerSec
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.max.tracker.failures is deprecated. Instead, use mapreduce.job.maxtaskfailures.per.tracker
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.jobtracker.split.metainfo.maxsize is deprecated. Instead, use mapreduce.job.split.metainfo.maxsize
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.persist.jobstatus.dir is deprecated. Instead, use mapreduce.jobtracker.persist.jobstatus.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - job.end.retry.attempts is deprecated. Instead, use mapreduce.job.end-notification.retry.attempts
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.safemode.threshold.pct is deprecated. Instead, use dfs.namenode.safemode.threshold-pct
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.tracker.task-controller is deprecated. Instead, use mapreduce.tasktracker.taskcontroller
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.jobtracker.maxtasks.per.job is deprecated. Instead, use mapreduce.jobtracker.maxtasks.perjob
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.child.log.level is deprecated. Instead, use mapreduce.reduce.log.level
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.max.attempts is deprecated. Instead, use mapreduce.reduce.maxattempts
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.http.address is deprecated. Instead, use dfs.namenode.http-address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.map.output.compression.codec is deprecated. Instead, use mapreduce.map.output.compress.codec
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.shuffle.input.buffer.percent is deprecated. Instead, use mapreduce.reduce.shuffle.input.buffer.percent
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.tracker.report.address is deprecated. Instead, use mapreduce.tasktracker.report.address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - keep.failed.task.files is deprecated. Instead, use mapreduce.task.files.preserve.failedtasks
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.used.genericoptionsparser is deprecated. Instead, use mapreduce.client.genericoptionsparser.used
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.name.dir.restore is deprecated. Instead, use dfs.namenode.name.dir.restore
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.https.client.keystore.resource is deprecated. Instead, use dfs.client.https.keystore.resource
 INFO main org.apache.hadoop.conf.Configuration.deprecation - tasktracker.http.threads is deprecated. Instead, use mapreduce.tasktracker.http.threads
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.speculative.execution.slowTaskThreshold is deprecated. Instead, use mapreduce.job.speculative.slowtaskthreshold
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.backup.address is deprecated. Instead, use dfs.namenode.backup.address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.backup.http.address is deprecated. Instead, use dfs.namenode.backup.http-address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.acls.enabled is deprecated. Instead, use mapreduce.cluster.acls.enabled
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.max.tracker.blacklists is deprecated. Instead, use mapreduce.jobtracker.tasktracker.maxblacklists
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.indexcache.mb is deprecated. Instead, use mapreduce.tasktracker.indexcache.mb
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.attempts.to.start.skipping is deprecated. Instead, use mapreduce.task.skip.start.attempts
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.reduce.tasks.maximum is deprecated. Instead, use mapreduce.tasktracker.reduce.tasks.maximum
 INFO main org.apache.hadoop.conf.Configuration.deprecation - jobclient.output.filter is deprecated. Instead, use mapreduce.client.output.filter
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.permissions is deprecated. Instead, use dfs.permissions.enabled
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.jobtracker.restart.recover is deprecated. Instead, use mapreduce.jobtracker.restart.recover
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.speculative.execution.speculativeCap is deprecated. Instead, use mapreduce.job.speculative.speculativecap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - jobclient.progress.monitor.poll.interval is deprecated. Instead, use mapreduce.client.progressmonitor.pollinterval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.safemode.extension is deprecated. Instead, use dfs.namenode.safemode.extension
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.datanode.max.xcievers is deprecated. Instead, use dfs.datanode.max.transfer.threads
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.map.child.log.level is deprecated. Instead, use mapreduce.map.log.level
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.retiredjobs.cache.size is deprecated. Instead, use mapreduce.jobtracker.retiredjobs.cache.size
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.https.need.client.auth is deprecated. Instead, use dfs.client.https.need-auth
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.dns.interface is deprecated. Instead, use mapreduce.tasktracker.dns.interface
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.profile.reduces is deprecated. Instead, use mapreduce.task.profile.reduces
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.https.address is deprecated. Instead, use dfs.namenode.https-address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - job.end.retry.interval is deprecated. Instead, use mapreduce.job.end-notification.retry.interval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.jobtracker.job.history.block.size is deprecated. Instead, use mapreduce.jobtracker.jobhistory.block.size
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.child.tmp is deprecated. Instead, use mapreduce.task.tmp.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.replication.interval is deprecated. Instead, use dfs.namenode.replication.interval
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.map.tasks.maximum is deprecated. Instead, use mapreduce.tasktracker.map.tasks.maximum
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
 INFO main org.apache.hadoop.conf.Configuration.deprecation - fs.checkpoint.edits.dir is deprecated. Instead, use dfs.namenode.checkpoint.edits.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.queue.name is deprecated. Instead, use mapreduce.job.queuename
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.write.packet.size is deprecated. Instead, use dfs.client-write-packet-size
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.jobtracker.taskScheduler is deprecated. Instead, use mapreduce.jobtracker.taskscheduler
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.reduce.max.skip.groups is deprecated. Instead, use mapreduce.reduce.skip.maxgroups
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.permissions.supergroup is deprecated. Instead, use dfs.permissions.superusergroup
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.healthChecker.script.timeout is deprecated. Instead, use mapreduce.tasktracker.healthchecker.script.timeout
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.instrumentation is deprecated. Instead, use mapreduce.tasktracker.instrumentation
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reuse.jvm.num.tasks is deprecated. Instead, use mapreduce.job.jvm.numtasks
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.system.dir is deprecated. Instead, use mapreduce.jobtracker.system.dir
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.inmem.merge.threshold is deprecated. Instead, use mapreduce.reduce.merge.inmem.threshold
 INFO main org.apache.hadoop.conf.Configuration.deprecation - topology.script.number.args is deprecated. Instead, use net.topology.script.number.args
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.slowstart.completed.maps is deprecated. Instead, use mapreduce.job.reduce.slowstart.completedmaps
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.umaskmode is deprecated. Instead, use fs.permissions.umask-mode
 INFO main org.apache.hadoop.conf.Configuration.deprecation - dfs.secondary.http.address is deprecated. Instead, use dfs.namenode.secondary.http-address
 INFO main org.apache.hadoop.conf.Configuration.deprecation - fs.checkpoint.period is deprecated. Instead, use dfs.namenode.checkpoint.period
 INFO main org.apache.hadoop.conf.Configuration.deprecation - topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tasktracker.tasks.sleeptime-before-sigkill is deprecated. Instead, use mapreduce.tasktracker.tasks.sleeptimebeforesigkill
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.merge.recordsBeforeProgress is deprecated. Instead, use mapreduce.task.merge.progress.records
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.shuffle.connect.timeout is deprecated. Instead, use mapreduce.reduce.shuffle.connect.timeout
 INFO main org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.HConstants, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.protobuf.generated.ClientProtos, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-protocol/0.98.8-hadoop2/hbase-protocol-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.client.Put, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-client/0.98.8-hadoop2/hbase-client-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.CompatibilityFactory, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-hadoop-compat/0.98.8-hadoop2/hbase-hadoop-compat-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.mapreduce.TableMapper, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-server/0.98.8-hadoop2/hbase-server-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.zookeeper.ZooKeeper, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.jboss.netty.channel.ChannelFactory, using jar /C:/Users/shanhongshu/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class com.google.protobuf.Message, using jar /C:/Users/shanhongshu/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class com.google.common.collect.Lists, using jar /C:/Users/shanhongshu/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.cloudera.htrace.Trace, using jar /C:/Users/shanhongshu/.m2/repository/org/cloudera/htrace/htrace-core/2.04/htrace-core-2.04.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.cliffc.high_scale_lib.Counter, using jar /C:/Users/shanhongshu/.m2/repository/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.io.ImmutableBytesWritable, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.KeyValue, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.mapreduce.TableInputFormat, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-server/0.98.8-hadoop2/hbase-server-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.io.ImmutableBytesWritable, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.KeyValue, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.2.0/hadoop-mapreduce-client-core-2.2.0.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.mapreduce.lib.partition.HashPartitioner, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.2.0/hadoop-mapreduce-client-core-2.2.0.jar
 INFO main org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
 INFO main org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.HConstants, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.protobuf.generated.ClientProtos, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-protocol/0.98.8-hadoop2/hbase-protocol-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.client.Put, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-client/0.98.8-hadoop2/hbase-client-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.CompatibilityFactory, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-hadoop-compat/0.98.8-hadoop2/hbase-hadoop-compat-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.mapreduce.TableMapper, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-server/0.98.8-hadoop2/hbase-server-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.zookeeper.ZooKeeper, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.jboss.netty.channel.ChannelFactory, using jar /C:/Users/shanhongshu/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class com.google.protobuf.Message, using jar /C:/Users/shanhongshu/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class com.google.common.collect.Lists, using jar /C:/Users/shanhongshu/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.cloudera.htrace.Trace, using jar /C:/Users/shanhongshu/.m2/repository/org/cloudera/htrace/htrace-core/2.04/htrace-core-2.04.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.cliffc.high_scale_lib.Counter, using jar /C:/Users/shanhongshu/.m2/repository/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.io.ImmutableBytesWritable, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.KeyValue, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.mapreduce.TableInputFormat, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-server/0.98.8-hadoop2/hbase-server-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.io.ImmutableBytesWritable, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-common/0.98.8-hadoop2/hbase-common-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.io.Writable, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hadoop/hadoop-common/2.2.0/hadoop-common-2.2.0.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.hbase.mapreduce.TableOutputFormat, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hbase/hbase-server/0.98.8-hadoop2/hbase-server-0.98.8-hadoop2.jar
 DEBUG main org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil - For class org.apache.hadoop.mapreduce.lib.partition.HashPartitioner, using jar /C:/Users/shanhongshu/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.2.0/hadoop-mapreduce-client-core-2.2.0.jar
 INFO main com.pxene.report.ReportMRHbase - ~~ Job configure complete  , waitForCompletion...
 DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:shanhongshu (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1233)
 DEBUG main org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 DEBUG main org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
 DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:shanhongshu (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:161)
 DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:shanhongshu (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1265)
 INFO main org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
 INFO main org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
 INFO main org.apache.hadoop.hbase.mapreduce.TableOutputFormat - Created table instance for dsp_tanx_usefull
 DEBUG main org.apache.hadoop.mapreduce.JobSubmitter - Configuring job job_local97777710_0001 with file:/tmp/hadoop-shanhongshu/mapred/staging/shanhongshu97777710/.staging/job_local97777710_0001 as the submit dir
 DEBUG main org.apache.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[file:///]
 DEBUG main org.apache.hadoop.mapreduce.JobSubmitter - default FileSystem: file:///
 WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 DEBUG main org.apache.hadoop.mapreduce.JobSubmitter - Creating splits at file:/tmp/hadoop-shanhongshu/mapred/staging/shanhongshu97777710/.staging/job_local97777710_0001
 ERROR main org.apache.hadoop.hbase.mapreduce.TableInputFormat - java.lang.IllegalArgumentException: Illegal character code:47, </> at 0. User-space table qualifiers can only contain 'alphanumeric characters': i.e. [a-zA-Z_0-9-.]: //master:9000/user/root/output
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:195)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:308)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:344)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:435)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:160)
	at org.apache.hadoop.hbase.mapreduce.TableInputFormat.setConf(TableInputFormat.java:109)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:488)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:508)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:392)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1268)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1265)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Unknown Source)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1265)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1286)
	at com.pxene.report.ReportMRHbase.main(ReportMRHbase.java:67)

 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop-shanhongshu/mapred/staging/shanhongshu97777710/.staging/job_local97777710_0001
 ERROR main org.apache.hadoop.security.UserGroupInformation - PriviledgedActionException as:shanhongshu (auth:SIMPLE) cause:java.io.IOException: No table was provided.
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x408629d1 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x408629d1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e13f, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x408629d1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x408629d1-0x24b2ef08b60e13f connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481958,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481958,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6d20f327, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,85900481958,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900481958,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 1
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 0, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 1 method_name: "DisableTable" request_param: true
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 1, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x408629d1 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x408629d1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6fcc8c5e
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb14163335a, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x408629d1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x408629d1-0x34b2fb14163335a connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481965,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x408629d1-0x34b2fb14163335a, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481965,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900481965,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Scan" request_param: true
 DEBUG IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 2
 DEBUG IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 2, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 3 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 4 method_name: "Scan" request_param: true
 DEBUG IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 4, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6fcc8c5e
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x34b2fb14163335a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x34b2fb14163335a
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335a, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900481968,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x34b2fb14163335a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x34b2fb14163335a closed
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x34b2fb14163335a : Unable to read additional data from server sessionid 0x34b2fb14163335a, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,85900481968,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a3630303030ffffffb6ffffff82ffffffddffffffdc1c3650555042554681,s{85900481925,85900481966,1422443699696,1422443895765,5,0,0,0,31,0,85900481925} 
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 5 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 5, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 6 method_name: "DeleteTable" request_param: true
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 6, totalSize: 4 bytes
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e13f, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,85900481969,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 7 method_name: "Scan" request_param: true
 DEBUG IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 7, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 8 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 8, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 9 method_name: "GetTableDescriptors" request_param: true
 DEBUG IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (681032536) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 9, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted dsp_tanx_usefull
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xd3d7fa1 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0xd3d7fa1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4df22, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xd3d7fa1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xd3d7fa1-0x14b2ef08aa4df22 connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481974,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481974,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@e1abbbd, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0xd3d7fa1 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0xd3d7fa1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@48783691
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e140, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0xd3d7fa1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0xd3d7fa1-0x24b2ef08b60e140 connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e140, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481975,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0xd3d7fa1-0x24b2ef08b60e140, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e140, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481975,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900481975,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x24b2ef08b60e140 after 37ms
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x14b2ef08aa4df22 after 26ms
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: closing ipc connection to pxene04/42.123.70.36:60020: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene04/42.123.70.36:60020]
 org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene04/42.123.70.36:60020]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:532)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:30387)
	at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:308)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:164)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:117)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:283)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:188)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:183)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:110)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:745)
	at org.apache.hadoop.hbase.catalog.MetaReader.fullScan(MetaReader.java:542)
	at org.apache.hadoop.hbase.catalog.MetaReader.tableExists(MetaReader.java:310)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:307)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:321)
	at com.pxene.report.Init.creatTable(Init.java:180)
	at com.pxene.report.Init.main(Init.java:70)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900481975,0  request:: '/hbase/table/hbase:meta,F  response:: #ffffffff000146d61737465723a3630303030ffffff814e2b576effffffacffffff95545042554680,s{42949673012,42949673013,1420690547175,1420690547194,1,0,0,0,31,0,42949673012} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900481975,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene04/42.123.70.36:60020 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: closing ipc connection to pxene04/42.123.70.36:60020: This server is in the failed servers list: pxene04/42.123.70.36:60020
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene04/42.123.70.36:60020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:30387)
	at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:308)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:164)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:117)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:283)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:188)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:183)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:110)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:745)
	at org.apache.hadoop.hbase.catalog.MetaReader.fullScan(MetaReader.java:542)
	at org.apache.hadoop.hbase.catalog.MetaReader.tableExists(MetaReader.java:310)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:307)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:321)
	at com.pxene.report.Init.creatTable(Init.java:180)
	at com.pxene.report.Init.main(Init.java:70)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,85900481975,0  request:: '/hbase/table/hbase:meta,F  response:: #ffffffff000146d61737465723a3630303030ffffff814e2b576effffffacffffff95545042554680,s{42949673012,42949673013,1420690547175,1420690547194,1,0,0,0,31,0,42949673012} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,85900481975,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene04/42.123.70.36:60020 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: closing ipc connection to pxene04/42.123.70.36:60020: This server is in the failed servers list: pxene04/42.123.70.36:60020
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene04/42.123.70.36:60020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:30387)
	at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:308)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:164)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:117)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:93)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:283)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:188)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:183)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:110)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:745)
	at org.apache.hadoop.hbase.catalog.MetaReader.fullScan(MetaReader.java:542)
	at org.apache.hadoop.hbase.catalog.MetaReader.tableExists(MetaReader.java:310)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:307)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:321)
	at com.pxene.report.Init.creatTable(Init.java:180)
	at com.pxene.report.Init.main(Init.java:70)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,85900481975,0  request:: '/hbase/table/hbase:meta,F  response:: #ffffffff000146d61737465723a3630303030ffffff814e2b576effffffacffffff95545042554680,s{42949673012,42949673013,1420690547175,1420690547194,1,0,0,0,31,0,42949673012} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,85900481975,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 3 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 3, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 4 cell_block_meta { length: 1881 }, totalSize: 1909 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 5 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 5, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@48783691
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x24b2ef08b60e140
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x24b2ef08b60e140
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e140, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900481976,0  request:: null response:: null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x24b2ef08b60e140 : Unable to read additional data from server sessionid 0x24b2ef08b60e140, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x24b2ef08b60e140
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x24b2ef08b60e140 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.conf.Configuration.deprecation - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 10,3  replyHeader:: 10,85900481976,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,85900481976,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 6 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 2
 DEBUG IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 6, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 7 method_name: "CreateTable" request_param: true
 DEBUG IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 7, totalSize: 4 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 12,4  replyHeader:: 12,85900481981,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 8 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 8, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 9 cell_block_meta { length: 1881 }, totalSize: 1909 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 10 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 10, totalSize: 11 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 13,4  replyHeader:: 13,85900481981,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 11 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 11, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 12 cell_block_meta { length: 1881 }, totalSize: 1909 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 13 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 13, totalSize: 11 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 14,4  replyHeader:: 14,85900481981,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 14 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 14, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 15 cell_block_meta { length: 1881 }, totalSize: 1909 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 16 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 16, totalSize: 11 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 15,4  replyHeader:: 15,85900481982,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 17 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 17, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 18 cell_block_meta { length: 2032 }, totalSize: 2062 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 19 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 19, totalSize: 11 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 16,4  replyHeader:: 16,85900481982,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 20 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 20, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 21 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 21 cell_block_meta { length: 2032 }, totalSize: 2062 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 22 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 22, totalSize: 11 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 17,4  replyHeader:: 17,85900481986,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 23 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 23, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 24 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 24 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 25 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 25, totalSize: 11 bytes
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0xd3d7fa1 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0xd3d7fa1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3aa368a4
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb14163335b, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0xd3d7fa1, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0xd3d7fa1-0x34b2fb14163335b connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481988,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0xd3d7fa1-0x34b2fb14163335b, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481988,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 18,4  replyHeader:: 18,85900481988,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 26 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 26, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 27 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 27 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 28 method_name: "Scan" request_param: true
 DEBUG IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (796073455) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 28, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3aa368a4
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x34b2fb14163335b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x34b2fb14163335b
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335b, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900481989,0  request:: null response:: null
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x34b2fb14163335b : Unable to read additional data from server sessionid 0x34b2fb14163335b, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x34b2fb14163335b
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x34b2fb14163335b closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df22, packet:: clientPath:null serverPath:null finished:false header:: 19,4  replyHeader:: 19,85900481989,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a36303030301affffffd87332ffffffbbfffffff83cffffffaf5042554680,s{85900481980,85900481984,1422444036169,1422444037351,2,0,0,0,31,0,85900481980} 
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1098e5da connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x1098e5da, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 WARN main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 1000ms before retry #0...
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 WARN main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 2000ms before retry #1...
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4df23, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1098e5da, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1098e5da-0x14b2ef08aa4df23 connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df23, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481991,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df23, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481991,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@66942944, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df23, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900481991,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df23, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900481991,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7c514cef connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x7c514cef, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 WARN main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 1000ms before retry #0...
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 WARN main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 2000ms before retry #1...
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 WARN main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownInput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
 java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(Unknown Source)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1185)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1110)
WARN main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Possibly transient ZooKeeper, quorum=pxene03:2181,pxene01:2181,pxene04:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
 INFO main org.apache.hadoop.hbase.util.RetryCounter - Sleeping 4000ms before retry #2...
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4df24, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7c514cef, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7c514cef-0x14b2ef08aa4df24 connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df24, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900481993,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df24, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900481993,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4e692639, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df24, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900481993,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df24, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900481993,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 485 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df24, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900481993,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x14b2ef08aa4df24 after 41ms
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 2377 }, totalSize: 2403 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG IPC Client (1103625735) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (1103625735) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1103625735) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 12 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x61f2e11b connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x61f2e11b, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e141, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x61f2e11b, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x61f2e11b-0x24b2ef08b60e141 connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e141, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482002,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e141, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482002,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@13997783, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e141, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900482002,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e141, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482002,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 485 bytes
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e141, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482002,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 2377 }, totalSize: 2403 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG IPC Client (885578400) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (885578400) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (885578400) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 12 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7de21f45 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x7de21f45, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene01/42.123.70.33:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene01/42.123.70.33:2181, initiating session
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene01/42.123.70.33:2181
 INFO main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene01/42.123.70.33:2181, sessionid = 0x14b2ef08aa4df25, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7de21f45, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7de21f45-0x14b2ef08aa4df25 connected
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482004,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482004,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4706c7b2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,85900482004,0  request:: '/hbase,F  response:: s{42949672962,42949672962,1420690150549,1420690150549,0,47,0,0,0,15,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482004,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffff836ffffffcbffffff9c377b6e2050425546a14a77078656e65303110ffffffe0ffffffd4318fffffff7fffffff9ffffffd0ffffffafffffffb229100,s{81635161042,81635161042,1422270940401,1422270940401,0,0,0,237283821770655351,53,0,81635161042} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene01/42.123.70.33:60000
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 0, totalSize: 6 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 1 method_name: "DisableTable" request_param: true
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 1, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x7de21f45 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x7de21f45, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4881cfee
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb14163335c, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x7de21f45, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x7de21f45-0x34b2fb14163335c connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482009,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x7de21f45-0x34b2fb14163335c, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482010,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482011,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 2
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Scan" request_param: true
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 2, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 3 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 4 method_name: "Scan" request_param: true
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 4, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4881cfee
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x34b2fb14163335c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x34b2fb14163335c
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335c, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900482012,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x34b2fb14163335c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x34b2fb14163335c closed
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x34b2fb14163335c : Unable to read additional data from server sessionid 0x34b2fb14163335c, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,85900482012,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a3630303030ffffff9f3e5313affffffe067ffffffd55042554682,s{85900481980,85900482007,1422444036169,1422445114917,4,0,0,0,31,0,85900481980} 
 DEBUG main org.apache.hadoop.hbase.client.HBaseAdmin - Sleeping= 100ms, waiting for all regions to be disabled in dsp_tanx_usefull
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=catalogtracker-on-hconnection-0x7de21f45 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=catalogtracker-on-hconnection-0x7de21f45, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7797c609
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb14163335d, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x7de21f45, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - catalogtracker-on-hconnection-0x7de21f45-0x34b2fb14163335d connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482015,0  request:: '/hbase/meta-region-server,T  response:: s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.hbase.zookeeper.ZKUtil - catalogtracker-on-hconnection-0x7de21f45-0x34b2fb14163335d, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482015,0  request:: '/hbase/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,85900482015,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 5 method_name: "Scan" request_param: true
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 5, totalSize: 15 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 6 cell_block_meta { length: 2377 }, totalSize: 2407 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 7 method_name: "Scan" request_param: true
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 7, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.hbase.catalog.CatalogTracker - Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7797c609
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x34b2fb14163335d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x34b2fb14163335d
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb14163335d, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,85900482016,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x34b2fb14163335d
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x34b2fb14163335d : Unable to read additional data from server sessionid 0x34b2fb14163335d, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x34b2fb14163335d closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,85900482016,0  request:: '/hbase/table/dsp_tanx_usefull,F  response:: #ffffffff000146d61737465723a36303030303316786b2bffffff86ffffffe81f5042554681,s{85900481980,85900482013,1422444036169,1422445115929,5,0,0,0,31,0,85900481980} 
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled dsp_tanx_usefull
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 8 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 8, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 9 method_name: "DeleteTable" request_param: true
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 9, totalSize: 4 bytes
 DEBUG main-SendThread(pxene01:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x14b2ef08aa4df25, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,85900482017,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 10 method_name: "Scan" request_param: true
 DEBUG IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 10, totalSize: 11 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 11 method_name: "IsMasterRunning" request_param: true
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 11, totalSize: 6 bytes
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: wrote request header call_id: 12 method_name: "GetTableDescriptors" request_param: true
 DEBUG IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (526647941) connection to pxene01/42.123.70.33:60000 from shanhongshu: got response header call_id: 12, totalSize: 4 bytes
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted dsp_tanx_usefull
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x654692d2 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x654692d2, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb1416333a8, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x654692d2, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x654692d2-0x34b2fb1416333a8 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333a8, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482456,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333a8, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482456,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@32bed4f, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333a8, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900482456,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333a8, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482456,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 460 bytes
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333a8, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482457,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 471 }, totalSize: 489 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG IPC Client (375658713) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (375658713) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (375658713) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 12 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x654692d2 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x654692d2, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e17d, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x654692d2, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x654692d2-0x24b2ef08b60e17d connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e17d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482468,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e17d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482468,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7b6aa1c3, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e17d, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900482469,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e17d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482469,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 460 bytes
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e17d, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482470,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 471 }, totalSize: 489 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG IPC Client (2097095745) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (2097095745) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (2097095745) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 12 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x654692d2 connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x654692d2, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene04/42.123.70.36:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene04/42.123.70.36:2181, initiating session
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene04/42.123.70.36:2181
 INFO main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene04/42.123.70.36:2181, sessionid = 0x34b2fb1416333b0, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x654692d2, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x654692d2-0x34b2fb1416333b0 connected
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333b0, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482502,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333b0, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482502,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@409319ef, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333b0, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900482502,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333b0, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482502,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 460 bytes
 DEBUG main-SendThread(pxene04:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x34b2fb1416333b0, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482503,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 471 }, totalSize: 489 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (439651085) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG IPC Client (439651085) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (439651085) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 1280 bytes
 WARN htable-pool1-t1 org.apache.hadoop.hbase.client.AsyncProcess - #1, table=test_report, attempt=1/35 failed 1 ops, last exception: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family mdid does not exist in region test_report,,1422426656080.4c3014f05a96d116362ea574b7bb51a3. in table 'test_report', {NAME => 'br', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '1', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
	at org.apache.hadoop.hbase.regionserver.HRegionServer.doBatchOp(HRegionServer.java:4488)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.doNonAtomicRegionMutation(HRegionServer.java:3665)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3554)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29949)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2029)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:112)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:92)
	at java.lang.Thread.run(Thread.java:745)
 on pxene03,60020,1422270940787, tracking started Wed Jan 28 19:58:22 CST 2015 - FAILED, NOT RETRYING ANYMORE
 DEBUG main org.apache.hadoop.hbase.client.HTable - test_report: One or more of the operations have failed - waiting for all operation in progress to finish (successfully or not)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7c514cef connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x7c514cef, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e186, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7c514cef, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7c514cef-0x24b2ef08b60e186 connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e186, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482516,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e186, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482516,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7f25ab41, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e186, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900482517,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e186, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482518,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 0 method_name: "Get" request_param: true
 DEBUG IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 0, totalSize: 460 bytes
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e186, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482520,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 1 cell_block_meta { length: 471 }, totalSize: 489 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG IPC Client (1305145116) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 2 method_name: "Multi" request_param: true
 DEBUG IPC Client (1305145116) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1305145116) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 2, totalSize: 12 bytes
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: shanhongshu
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:shanhongshu (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x3d1bb20d connecting to ZooKeeper ensemble=pxene03:2181,pxene01:2181,pxene04:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=user-PC
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_60-ea
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=C:\work\Java\jre7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=C:\work\git_repo\dsp-report\target\test-classes;C:\work\git_repo\dsp-report\target\classes;C:\work\Java\jdk1.7.0_60\lib\tools.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-client\0.98.8-hadoop2\hbase-client-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-annotations\0.98.8-hadoop2\hbase-annotations-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;C:\Users\shanhongshu\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\shanhongshu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\shanhongshu\.m2\repository\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\shanhongshu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\shanhongshu\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\shanhongshu\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\shanhongshu\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\shanhongshu\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\shanhongshu\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\shanhongshu\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\shanhongshu\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\shanhongshu\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\shanhongshu\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\shanhongshu\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\shanhongshu\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\shanhongshu\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\shanhongshu\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\shanhongshu\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\shanhongshu\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\shanhongshu\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\shanhongshu\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\shanhongshu\.m2\repository\junit\junit\4.11\junit-4.11.jar;C:\Users\shanhongshu\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\shanhongshu\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-server\0.98.8-hadoop2\hbase-server-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-prefix-tree\0.98.8-hadoop2\hbase-prefix-tree-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-common\0.98.8-hadoop2\hbase-common-0.98.8-hadoop2-tests.jar;C:\Users\shanhongshu\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop-compat\0.98.8-hadoop2\hbase-hadoop-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-hadoop2-compat\0.98.8-hadoop2\hbase-hadoop2-compat-0.98.8-hadoop2.jar;C:\Users\shanhongshu\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\shanhongshu\.m2\repository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\shanhongshu\.m2\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-client\2.2.0\hadoop-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.2.0\hadoop-mapreduce-client-app-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.2.0\hadoop-mapreduce-client-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-grizzly2\1.9\jersey-test-framework-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-test-framework\jersey-test-framework-core\1.9\jersey-test-framework-core-1.9.jar;C:\Users\shanhongshu\.m2\repository\javax\servlet\javax.servlet-api\3.0.1\javax.servlet-api-3.0.1.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-grizzly2\1.9\jersey-grizzly2-1.9.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http\2.1.2\grizzly-http-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-framework\2.1.2\grizzly-framework-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\gmbal\gmbal-api-only\3.0.0-b023\gmbal-api-only-3.0.0-b023.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\external\management-api\3.0.0-b012\management-api-3.0.0-b012.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-server\2.1.2\grizzly-http-server-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-rcm\2.1.2\grizzly-rcm-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\grizzly\grizzly-http-servlet\2.1.2\grizzly-http-servlet-2.1.2.jar;C:\Users\shanhongshu\.m2\repository\org\glassfish\javax.servlet\3.1\javax.servlet-3.1.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.2.0\hadoop-mapreduce-client-shuffle-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.2.0\hadoop-yarn-api-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.2.0\hadoop-mapreduce-client-jobclient-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;C:\Users\shanhongshu\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\shanhongshu\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\shanhongshu\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\shanhongshu\.m2\repository\org\apache\hbase\hbase-protocol\0.98.8-hadoop2\hbase-protocol-0.98.8-hadoop2.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=C:\work\Java\jre7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\work\TortoiseGit\bin;C:\work\Java\jdk1.7.0_60\bin;C:\work\apache-maven-3.2.5-bin\apache-maven-3.2.5\bin;C:\work\workspace\hadoop-2.5.2\hadoop-2.5.2\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\SHANHO~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\shanhongshu
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=C:\work\git_repo\dsp-report
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=pxene03:2181,pxene01:2181,pxene04:2181 sessionTimeout=90000 watcher=hconnection-0x3d1bb20d, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server pxene03/42.123.70.35:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to pxene03/42.123.70.35:2181, initiating session
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on pxene03/42.123.70.35:2181
 INFO main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server pxene03/42.123.70.35:2181, sessionid = 0x24b2ef08b60e190, negotiated timeout = 40000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3d1bb20d, quorum=pxene03:2181,pxene01:2181,pxene04:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3d1bb20d-0x24b2ef08b60e190 connected
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,85900482552,0  request:: '/hbase/hbaseid,F  response:: s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,85900482552,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffc3ffffffe17510ffffff83ffffff80ffffffc7ffffffa250425546a2434383464346430372d613733322d346231372d623335662d396435376261373063643037,s{42949672972,81635161066,1420690152854,1422270941662,4,0,0,0,67,0,42949672972} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@297b0d9d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,85900482552,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,85900482552,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x24b2ef08b60e190 after 44ms
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: closing ipc connection to pxene04/42.123.70.36:60020: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene04/42.123.70.36:60020]
 org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=pxene04/42.123.70.36:60020]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:532)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.get(ClientProtos.java:30363)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRowOrBefore(ProtobufUtil.java:1546)
	at org.apache.hadoop.hbase.client.HTable$2.call(HTable.java:717)
	at org.apache.hadoop.hbase.client.HTable$2.call(HTable.java:715)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:117)
	at org.apache.hadoop.hbase.client.HTable.getRowOrBefore(HTable.java:721)
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:144)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1140)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1202)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1092)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1049)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:374)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:319)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:971)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1287)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:917)
	at com.pxene.report.Init.addRecord(Init.java:227)
	at com.pxene.report.Init.main(Init.java:71)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,85900482564,0  request:: '/hbase/table/hbase:meta,F  response:: #ffffffff000146d61737465723a3630303030ffffff814e2b576effffffacffffff95545042554680,s{42949673012,42949673013,1420690547175,1420690547194,1,0,0,0,31,0,42949673012} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,85900482564,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene04/42.123.70.36:60020 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: closing ipc connection to pxene04/42.123.70.36:60020: This server is in the failed servers list: pxene04/42.123.70.36:60020
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene04/42.123.70.36:60020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.get(ClientProtos.java:30363)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRowOrBefore(ProtobufUtil.java:1546)
	at org.apache.hadoop.hbase.client.HTable$2.call(HTable.java:717)
	at org.apache.hadoop.hbase.client.HTable$2.call(HTable.java:715)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:117)
	at org.apache.hadoop.hbase.client.HTable.getRowOrBefore(HTable.java:721)
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:144)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1140)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1202)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1092)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1049)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:374)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:319)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:971)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1287)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:917)
	at com.pxene.report.Init.addRecord(Init.java:227)
	at com.pxene.report.Init.main(Init.java:71)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,85900482564,0  request:: '/hbase/table/hbase:meta,F  response:: #ffffffff000146d61737465723a3630303030ffffff814e2b576effffffacffffff95545042554680,s{42949673012,42949673013,1420690547175,1420690547194,1,0,0,0,31,0,42949673012} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,85900482564,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Not trying to connect to pxene04/42.123.70.36:60020 this server is in the failed servers list
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: closing ipc connection to pxene04/42.123.70.36:60020: This server is in the failed servers list: pxene04/42.123.70.36:60020
 org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: pxene04/42.123.70.36:60020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.get(ClientProtos.java:30363)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRowOrBefore(ProtobufUtil.java:1546)
	at org.apache.hadoop.hbase.client.HTable$2.call(HTable.java:717)
	at org.apache.hadoop.hbase.client.HTable$2.call(HTable.java:715)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:117)
	at org.apache.hadoop.hbase.client.HTable.getRowOrBefore(HTable.java:721)
	at org.apache.hadoop.hbase.client.MetaScanner.metaScan(MetaScanner.java:144)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.prefetchRegionCache(HConnectionManager.java:1140)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegionInMeta(HConnectionManager.java:1202)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1092)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.locateRegion(HConnectionManager.java:1049)
	at org.apache.hadoop.hbase.client.AsyncProcess.findDestLocation(AsyncProcess.java:374)
	at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:319)
	at org.apache.hadoop.hbase.client.HTable.backgroundFlushCommits(HTable.java:971)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1287)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:917)
	at com.pxene.report.Init.addRecord(Init.java:227)
	at com.pxene.report.Init.main(Init.java:71)
DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: closed
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,85900482565,0  request:: '/hbase/table/hbase:meta,F  response:: #ffffffff000146d61737465723a3630303030ffffff814e2b576effffffacffffff95545042554680,s{42949673012,42949673013,1420690547175,1420690547194,1,0,0,0,31,0,42949673012} 
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 10,4  replyHeader:: 10,85900482565,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.ipc.RpcClient - Connecting to pxene04/42.123.70.36:60020
 DEBUG IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: starting, connections 1
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 3 method_name: "Get" request_param: true
 DEBUG IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 3, totalSize: 460 bytes
 DEBUG main-SendThread(pxene03:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x24b2ef08b60e190, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,85900482565,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffffd8ffffffc8ffffffbcffffff8effffffe823ffffffb9ffffff9850425546a14a77078656e65303410fffffff4ffffffd4318ffffff8dffffff8bffffffd1ffffffafffffffb229100183,s{81635161164,81635161164,1422270948149,1422270948149,0,0,0,0,61,0,81635161164} 
 DEBUG main org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
 DEBUG IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene04/42.123.70.36:60020 from shanhongshu: got response header call_id: 4 cell_block_meta { length: 471 }, totalSize: 489 bytes
 DEBUG main org.apache.hadoop.hbase.client.ClientSmallScanner - Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - Connecting to pxene03/42.123.70.35:60020
 DEBUG htable-pool1-t1 org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene03/42.123.70.35:60020 from shanhongshu: wrote request header call_id: 5 method_name: "Multi" request_param: true
 DEBUG IPC Client (1358595915) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene03/42.123.70.35:60020 from shanhongshu: starting, connections 2
 DEBUG IPC Client (1358595915) connection to pxene03/42.123.70.35:60020 from shanhongshu org.apache.hadoop.ipc.RpcClient - IPC Client (1358595915) connection to pxene03/42.123.70.35:60020 from shanhongshu: got response header call_id: 5, totalSize: 12 bytes
 